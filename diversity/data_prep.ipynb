{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code reads in selection tables created in Raven Pro and prepares the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pyarrow\n",
    "from datetime import datetime, timedelta\n",
    "from noaa_coops import Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path Configuration\n",
    "\n",
    "# Round 1 20 Hz to 24 kHz\n",
    "filepaths = [\n",
    "    \"/Volumes/SeaBABELa/BVI Mangroves_2024/BVI Mangroves_2024_Working/6863_Paraquita/6863_Paraquita_Raven/BVI_mangroves_6863_20240115_174358.diversity.selections.txt\",\n",
    "    \"/Volumes/SeaBABELa/BVI Mangroves_2024/BVI Mangroves_2024_Working/6879_French/6879_French_Raven/BVI_mangroves_6879_20240115_151620_list.diversity.selections.txt\",\n",
    "    \"/Volumes/SeaBABELa/BVI Mangroves_2024/BVI Mangroves_2024_Working/6880_HansA/6880_HansA_Raven/BVI_mangroves_6880_20240116_162417_list.diversity.selections.txt\",\n",
    "    \"/Volumes/SeaBABELa/BVI Mangroves_2024/BVI Mangroves_2024_Working/6884_SeaCowBay/6884_SeaCowBay_Raven/BVI_mangroves_6864_20240114_194526.diversity.selections.txt\"\n",
    "]\n",
    "\n",
    "# --- Initialize List for DataFrames ---\n",
    "dfs = []\n",
    "\n",
    "# --- Loop Through Files, Read, and Initial Processing ---\n",
    "for file in filepaths:\n",
    "    df = pd.read_csv(file, sep='\\t', engine='python')\n",
    "    df['file'] = file\n",
    "\n",
    "    # Drop Unwanted Columns\n",
    "    df = df.drop(columns=['Channel', 'From', 'Tags', 'View'], errors='ignore')\n",
    "\n",
    "    # Rename Columns\n",
    "    rename_cols = {\n",
    "        'Selection': 'selection',\n",
    "        'Begin Time (s)': 'begin_time_s',\n",
    "        'End Time (s)': 'end_time_s',\n",
    "        'Low Freq (Hz)': 'low_freq_hz',\n",
    "        'High Freq (Hz)': 'high_freq_hz',\n",
    "        'Begin Path': 'begin_path',\n",
    "        'File Offset (s)': 'file_offset_s',\n",
    "        'Peak Freq (Hz)': 'peak_freq_hz',\n",
    "        'Label': 'label'\n",
    "    }\n",
    "    df = df.rename(columns=rename_cols)\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "# --- Combine All DataFrames ---\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hydrophone number (list as site)\n",
    "df['site'] = df['file'].str.extract(r'BVI_mangroves_(\\d{4})_').astype(float)\n",
    "\n",
    "# Extract Date, Time, and Hour from 'begin_path' Filename\n",
    "date_time_match = df['begin_path'].str.extract(r'(\\d{8})_(\\d{6})')\n",
    "\n",
    "if date_time_match.notna().all().all():\n",
    "    df['extracted_date_str'] = date_time_match[0]\n",
    "    df['extracted_time_str'] = date_time_match[1]\n",
    "    df['extracted_datetime'] = pd.to_datetime(df['extracted_date_str'] + df['extracted_time_str'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "    # Add 'file_offset_s' as a Timedelta\n",
    "    df['adjusted_datetime'] = df['extracted_datetime'] + pd.to_timedelta(df['file_offset_s'], unit='s')\n",
    "\n",
    "    # Update 'date', 'time', and 'hour' from the adjusted datetime\n",
    "    df['date'] = df['adjusted_datetime'].dt.date\n",
    "    df['time'] = df['adjusted_datetime'].dt.strftime('%H%M%S')\n",
    "    df['hour'] = df['adjusted_datetime'].dt.hour.astype(float)\n",
    "\n",
    "    #Convert date to proper datetime.\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize('UTC')\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df = df.drop(columns=['extracted_date_str', 'extracted_time_str', 'extracted_datetime', 'adjusted_datetime'])\n",
    "else:\n",
    "    print(\"Warning: Could not extract date and time information from the filename in 'begin_path' in all rows. Please check the format.\")\n",
    "    df['date'] = pd.NaT\n",
    "    df['time'] = None\n",
    "    df['hour'] = None\n",
    "\n",
    "# --- Create 'tod' Column based on 'hour' ---\n",
    "def get_tod(hour):\n",
    "    if hour in [3, 4, 5]:\n",
    "        return 'midnight'\n",
    "    elif hour in [9, 10, 11]:\n",
    "        return 'sunrise'\n",
    "    elif hour in [15, 16, 17]:\n",
    "        return 'noon'\n",
    "    elif hour in [19, 20, 21, 22, 23]:\n",
    "        return 'sunset'\n",
    "    return None\n",
    "\n",
    "df['tod'] = df['hour'].apply(get_tod)\n",
    "\n",
    "# --- Fetch Tidal Data ---\n",
    "# NOAA CO-OPS Station Setup\n",
    "usvi = Station(id=\"9751419\")  # HAULOVER BAY, ST. JOHNS, PR\n",
    "\n",
    "# Determine the date range from your DataFrame\n",
    "start_date = df['date'].min()\n",
    "end_date = df['date'].max()\n",
    "\n",
    "# Fetch tidal data in UTC\n",
    "df_tides = usvi.get_data(\n",
    "    begin_date=start_date.strftime('%Y%m%d'),\n",
    "    end_date=end_date.strftime('%Y%m%d'),\n",
    "    product=\"predictions\",\n",
    "    datum=\"MLLW\", # Mean Lower Low Water provides a conservative estimate of the lowest possible water levels.\n",
    "    units=\"metric\",\n",
    "    time_zone=\"gmt\" # important change.\n",
    ")\n",
    "\n",
    "# Ensure datetime-aware timestamps\n",
    "df_tides.index = pd.to_datetime(df_tides.index).tz_localize(\"UTC\")\n",
    "\n",
    "# Merge tidal height data into your DataFrame\n",
    "df = pd.merge_asof(\n",
    "    df.sort_values('date'),\n",
    "    df_tides[['v']].sort_index(),\n",
    "    left_on='date',\n",
    "    right_index=True,\n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "# Rename tidal column (not working??)\n",
    "df_tides.rename(columns={'v': 'mllw'}, inplace=True)\n",
    "\n",
    "# --- Summarize 'tod' counts by 'date' and 'site' ---\n",
    "tod_summary = df.groupby(['date', 'site', 'tod']).size().unstack(fill_value=0)\n",
    "\n",
    "# --- Display the Summary ---\n",
    "print(\"\\nSummary of Time of Day (tod) counts by Date and Site (Adjusted Time from begin_path filename):\")\n",
    "print(tod_summary)\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\nHead of the processed DataFrame (Adjusted Time from begin_path filename):\")\n",
    "print(df.head())\n",
    "print(\"\\nColumns of the processed DataFrame:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the main DataFrame to CSV or parquet\n",
    "df.to_parquet('/Users/jillmunger/Desktop/UNH/research/diversity/div_data_tide.parquet', index=False)\n",
    "\n",
    "df.to_csv('/Users/jillmunger/Desktop/UNH/research/diversity/div_data_tide.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tides' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# --- Plot just the MLLW tide level over time ---\u001b[39;00m\n\u001b[32m      4\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m plt.plot(\u001b[43mdf_tides\u001b[49m.index, df_tides[\u001b[33m'\u001b[39m\u001b[33mmllw\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTide Height (MLLW)\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33msteelblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mDate & Time (UTC)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mTide Height (meters)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_tides' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Plot just the MLLW tide level over time ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_tides.index, df_tides['mllw'], label='Tide Height (MLLW)', color='steelblue')\n",
    "plt.xlabel('Date & Time (UTC)')\n",
    "plt.ylabel('Tide Height (meters)')\n",
    "plt.title('NOAA Predicted Tidal Levels (MLLW Datum)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.11 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a84b1fe7ab28d062d393c3dead09877d57930c2730b99ff46e42d74baaf02ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
